{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select, create_engine, func, tablesample\n",
    "from sqlalchemy.orm import aliased\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import LocalCluster\n",
    "\n",
    "from telegram_data_models import Message, Chat, MessageTextContent, Entity\n",
    "from telegram_quality_control.chat_language import ChatLanguage\n",
    "from telegram_quality_control.db import get_conn_string\n",
    "from telegram_quality_control.cleaning import batch_clean_text\n",
    "from telegram_quality_control.topics import Embeddings, Topics\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dae59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "test_run = False\n",
    "\n",
    "language = \"english\"\n",
    "language_code = \"en\"\n",
    "lang_score = 0.8\n",
    "\n",
    "embedding_model = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "\n",
    "if test_run:\n",
    "    num_messages = 100\n",
    "    min_cluster_size = 3\n",
    "    folder_tag = f\"{language_code}_test\"\n",
    "else:\n",
    "    num_messages = 1_000_000\n",
    "    if language_code == \"en\":\n",
    "        # For English, min_cluster_size has to be a bit larger, because otherwise we run into this bug:\n",
    "        # https://github.com/rapidsai/cuml/issues/3568#issuecomment-788316039\n",
    "        min_cluster_size = 25\n",
    "    else:\n",
    "        min_cluster_size = 20\n",
    "    folder_tag = f\"{language_code}_{num_messages}_messages_full\"\n",
    "\n",
    "min_message_length = 50\n",
    "\n",
    "min_samples = min_cluster_size\n",
    "\n",
    "scratch_folder = Path(os.environ.get(\"SCRATCH_FOLDER\"))\n",
    "print(f\"Scratch folder: {scratch_folder}\")\n",
    "scratch_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_folder = Path(os.environ.get(\"OUTPUT_FOLDER\"))\n",
    "print(f\"Data folder: {data_folder}\")\n",
    "data_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "message_folder = scratch_folder / f\"clean_messages\" / folder_tag\n",
    "message_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bee74",
   "metadata": {},
   "source": [
    "## Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7422b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = get_conn_string(\".env\")\n",
    "\n",
    "message_table = Message.__table__\n",
    "language_table = ChatLanguage.__table__\n",
    "content_table = MessageTextContent.__table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get message ids first\n",
    "if language_code == \"ru\":\n",
    "    frac = 0.5  # 0.5%\n",
    "elif language_code == \"fa\" or language_code == \"ar\":\n",
    "    frac = 1  # 1%\n",
    "elif language_code == \"en\":\n",
    "    frac = 2\n",
    "else:\n",
    "    frac = 4\n",
    "message_sample = aliased(Message, tablesample(Message, func.bernoulli(frac)))\n",
    "# message_sample = aliased(Message, tablesample(Message, func.system(1)))\n",
    "\n",
    "sql = (\n",
    "    select(message_sample.id)\n",
    "    .join(ChatLanguage, ChatLanguage.chat_id == message_sample.chat_id)\n",
    "    .join(MessageTextContent, MessageTextContent.message_id == message_sample.id)\n",
    "    # filter for language\n",
    "    .where(ChatLanguage.lang == language_code)\n",
    "    .where(ChatLanguage.score > 0.8)\n",
    "    # filter out short documents\n",
    "    .where(\n",
    "        (func.length(MessageTextContent.text) > min_message_length)\n",
    "        | (func.length(MessageTextContent.caption) > min_message_length)\n",
    "    )\n",
    ")\n",
    "\n",
    "if test_run:\n",
    "    # do not really randomly shuffle\n",
    "    sql = sql.limit(num_messages * 10)\n",
    "\n",
    "message_ids = pd.read_sql(sql, db_url, index_col=\"id\")\n",
    "\n",
    "print(f\"Got {len(message_ids)} messages\")\n",
    "\n",
    "# sample twice as many messages, so that there will be enough left after cleaning\n",
    "if len(message_ids) > num_messages * 2:\n",
    "    message_ids = message_ids.sample(n=num_messages * 2)\n",
    "\n",
    "message_ids.to_csv(message_folder / \"message_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97948252",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_ids = pd.read_csv(message_folder / \"message_ids.csv\")\n",
    "message_ids = message_ids[\"id\"].to_list()\n",
    "message_ids.sort()\n",
    "\n",
    "sql = select(\n",
    "    MessageTextContent.message_id,\n",
    "    func.coalesce(MessageTextContent.text, MessageTextContent.caption).label('content'),\n",
    ").where(MessageTextContent.message_id.in_(message_ids))\n",
    "\n",
    "engine = create_engine(db_url)\n",
    "with engine.connect() as conn:\n",
    "    messages = pd.read_sql(sql, conn)\n",
    "\n",
    "print(f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Extracted {len(messages)} messages\")\n",
    "\n",
    "# filter out system messages\n",
    "system_messages = [\n",
    "    \"This message couldn't be displayed on your device due to copyright infringement.\",\n",
    "    \"This channel can’t be displayed because it violated Telegram's Terms of Service.\",\n",
    "    \"This channel can’t be displayed because it violated local laws.\",\n",
    "]\n",
    "\n",
    "messages = messages[~messages[[\"content\"]].isin(system_messages).any(axis=1)]\n",
    "\n",
    "print(\n",
    "    f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Filtered out system messages, left with {len(messages)} messages\"\n",
    ")\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[\"clean_text\"] = batch_clean_text(messages[\"content\"])\n",
    "\n",
    "messages = messages[messages[\"clean_text\"].str.len() >= min_message_length]\n",
    "\n",
    "print(\n",
    "    f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Cleaned messages and removed too short ones, left with {len(messages)} messages\"\n",
    ")\n",
    "\n",
    "if len(messages) > num_messages:\n",
    "    messages = messages.sample(n=num_messages)\n",
    "    print(f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Sampled to {len(messages)} messages\")\n",
    "else:\n",
    "    print(\n",
    "        f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Number of messages already below {num_messages}\"\n",
    "    )\n",
    "\n",
    "# save messages\n",
    "messages.to_parquet(message_folder / \"messages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_parquet(message_folder / \"messages.parquet\")\n",
    "\n",
    "docs = messages[\"clean_text\"].tolist()\n",
    "\n",
    "print(f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Loaded {len(docs)} documents\")\n",
    "\n",
    "embedding_cache = Embeddings(folder_tag, embedding_model=embedding_model)\n",
    "embeddings = embedding_cache.create(docs)\n",
    "embedding_cache.save()\n",
    "\n",
    "print(f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Calculated embeddings\")\n",
    "\n",
    "topic_cache = Topics(\n",
    "    folder_tag, text_language=language, min_samples=min_samples, min_cluster_size=min_cluster_size\n",
    ")\n",
    "topic_model, topics, probs = topic_cache.create(docs, embeddings, embedding_cache.embedding_model)\n",
    "topic_cache.save()\n",
    "\n",
    "print(f\"[{datetime.now().strftime(\"%H:%M:%S\")}] Finished classifying topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe20e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = len(topic_model.get_topic_info())\n",
    "print(f\"Number of discovered topics: {n_topics}\")\n",
    "\n",
    "# Print top-20 topics with their counts\n",
    "topic_info = topic_model.get_topic_info()\n",
    "top_20 = topic_info.head(20)\n",
    "\n",
    "not_classified_count = topic_info['Count'].values[0]\n",
    "fraction_unclassified = not_classified_count / num_messages * 100\n",
    "print(f\"Fraction of unclassified documents: {fraction_unclassified:.2f}%\")\n",
    "\n",
    "print(\"\\nTop-20 Topics:\")\n",
    "for _, row in top_20.iterrows():\n",
    "    print(f\"Topic {row['Name']}: {row['Count']} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram-quality-control-py3.12 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
