{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from telegram_toolchain.data.database import get_conn\n",
    "from telegram_data_models import Message, Chat, MessageTextContent, Queue\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads .env from cwd (or parents)\n",
    "load_dotenv(\"../../credentials/credentials.env\")\n",
    "from sqlalchemy import select, func, case, create_engine\n",
    "from tqdm.auto import tqdm  # works in both notebooks & terminals\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import LogLocator, LogFormatterMathtext, NullFormatter\n",
    "\n",
    "from cmcrameri import cm\n",
    "\n",
    "plt.style.use('../../resources/mpl_styles/default.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def _get_positive_xy(df, x_col, y_col, *, log_base=np.e, mask=None):\n",
    "    \"\"\"\n",
    "    Extract x,y arrays; keep strictly positive; apply optional extra mask;\n",
    "    return x_pos, y_pos, X=log(x), Y=log(y), and final mask.\n",
    "    \"\"\"\n",
    "    x = df[x_col].to_numpy(dtype=float)\n",
    "    y = df[y_col].to_numpy(dtype=float)\n",
    "\n",
    "    m = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)\n",
    "    if mask is not None:\n",
    "        m = m & mask\n",
    "\n",
    "    x_pos = x[m]\n",
    "    y_pos = y[m]\n",
    "\n",
    "    if x_pos.size == 0:\n",
    "        raise ValueError(\"No strictly positive finite points in both x and y after masking.\")\n",
    "\n",
    "    if log_base == 10:\n",
    "        X = np.log10(x_pos)\n",
    "        Y = np.log10(y_pos)\n",
    "    elif log_base in (np.e, None):\n",
    "        X = np.log(x_pos)\n",
    "        Y = np.log(y_pos)\n",
    "    else:\n",
    "        # change of base: log_b(x) = ln(x)/ln(b)\n",
    "        X = np.log(x_pos) / np.log(log_base)\n",
    "        Y = np.log(y_pos) / np.log(log_base)\n",
    "\n",
    "    return x_pos, y_pos, X, Y, m\n",
    "\n",
    "\n",
    "def _line_params_to_powerlaw(a, b, *, log_base=np.e):\n",
    "    \"\"\"\n",
    "    If fitting log y = a + b log x with log base 'log_base':\n",
    "    returns multiplicative constant c s.t. y = c * x^b.\n",
    "    \"\"\"\n",
    "    if log_base == 10:\n",
    "        # log10 y = a + b log10 x  => y = 10^a * x^b\n",
    "        c = 10**a\n",
    "    elif log_base in (np.e, None):\n",
    "        # ln y = a + b ln x => y = exp(a) * x^b\n",
    "        c = np.exp(a)\n",
    "    else:\n",
    "        # y = (log_base)^a * x^b\n",
    "        c = log_base**a\n",
    "    return c\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Correlation measures\n",
    "# -----------------------------\n",
    "def correlation_measures(df, x_col, y_col, *, log_base=10, mask=None):\n",
    "    \"\"\"\n",
    "    Returns correlation measures on log-transformed x,y:\n",
    "      - Pearson r in log space\n",
    "      - Spearman rho on (x,y) (equivalent to on logs since monotonic)\n",
    "      - Kendall tau on (x,y)\n",
    "    \"\"\"\n",
    "    from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    pearson_r, pearson_p = pearsonr(X, Y)\n",
    "    spear_rho, spear_p = spearmanr(X, Y)  # using X,Y is fine; ranks same as x,y\n",
    "    kend_tau, kend_p = kendalltau(X, Y)\n",
    "\n",
    "    return {\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"pearson_r_log\": float(pearson_r),\n",
    "        \"pearson_p\": float(pearson_p),\n",
    "        \"spearman_rho\": float(spear_rho),\n",
    "        \"spearman_p\": float(spear_p),\n",
    "        \"kendall_tau\": float(kend_tau),\n",
    "        \"kendall_p\": float(kend_p),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Line fits in log-log space\n",
    "# Each returns a dict:\n",
    "#  - method, a, b for log y = a + b log x\n",
    "#  - c for y = c * x^b\n",
    "#  - plus optional diagnostics\n",
    "# -----------------------------\n",
    "def fit_loglog_ols(df, x_col, y_col, *, log_base=10, mask=None):\n",
    "    \"\"\"Ordinary least squares of Y on X in log space.\"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    res = stats.linregress(X, Y)\n",
    "    a = res.intercept\n",
    "    b = res.slope\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"ols\",\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": float(a),\n",
    "        \"b\": float(b),\n",
    "        \"c\": float(c),\n",
    "        \"rvalue\": float(res.rvalue),\n",
    "        \"pvalue\": float(res.pvalue),\n",
    "        \"stderr_slope\": float(res.stderr),\n",
    "        \"stderr_intercept\": float(res.intercept_stderr),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_loglog_tls(df, x_col, y_col, *, log_base=10, mask=None):\n",
    "    \"\"\"\n",
    "    Total least squares / orthogonal regression in log space via SVD.\n",
    "    Minimizes squared perpendicular distances.\n",
    "    \"\"\"\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    Xc = X - X.mean()\n",
    "    Yc = Y - Y.mean()\n",
    "    A = np.vstack([Xc, Yc]).T\n",
    "    # first principal component\n",
    "    _, _, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "    vx, vy = Vt[0, 0], Vt[0, 1]\n",
    "    if np.isclose(vx, 0):\n",
    "        raise ValueError(\"TLS failed: vx ~ 0 (vertical line in log space).\")\n",
    "\n",
    "    b = vy / vx\n",
    "    a = Y.mean() - b * X.mean()\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    # orthogonal residual RMS (in log units)\n",
    "    # distance from point to line: |bX - Y + a| / sqrt(b^2 + 1)\n",
    "    ortho = np.abs(b * X - Y + a) / np.sqrt(b * b + 1)\n",
    "    return {\n",
    "        \"method\": \"tls\",\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": float(a),\n",
    "        \"b\": float(b),\n",
    "        \"c\": float(c),\n",
    "        \"ortho_rms\": float(np.sqrt(np.mean(ortho**2))),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_loglog_theilsen(df, x_col, y_col, *, log_base=10, mask=None, random_state=0):\n",
    "    \"\"\"Theil–Sen robust line fit in log space.\"\"\"\n",
    "    from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    model = TheilSenRegressor(random_state=random_state)\n",
    "    model.fit(X.reshape(-1, 1), Y)\n",
    "    b = float(model.coef_[0])\n",
    "    a = float(model.intercept_)\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"theil_sen\",\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": a,\n",
    "        \"b\": b,\n",
    "        \"c\": float(c),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_loglog_huber(df, x_col, y_col, *, log_base=10, mask=None, epsilon=1.35):\n",
    "    \"\"\"Huber robust regression in log space.\"\"\"\n",
    "    from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    model = HuberRegressor(epsilon=epsilon)\n",
    "    model.fit(X.reshape(-1, 1), Y)\n",
    "    b = float(model.coef_[0])\n",
    "    a = float(model.intercept_)\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"huber\",\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": a,\n",
    "        \"b\": b,\n",
    "        \"c\": float(c),\n",
    "        \"epsilon\": float(epsilon),\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_loglog_ransac(\n",
    "    df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    *,\n",
    "    log_base=10,\n",
    "    mask=None,\n",
    "    min_samples=0.5,\n",
    "    residual_threshold=None,\n",
    "    random_state=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    RANSAC line fit in log space (robust to lots of outliers).\n",
    "    residual_threshold is in log-units; if None, sklearn chooses heuristic.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    base = LinearRegression()\n",
    "    model = RANSACRegressor(\n",
    "        estimator=base,\n",
    "        min_samples=min_samples,\n",
    "        residual_threshold=residual_threshold,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    model.fit(X.reshape(-1, 1), Y)\n",
    "\n",
    "    b = float(model.estimator_.coef_[0])\n",
    "    a = float(model.estimator_.intercept_)\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    inlier_mask = model.inlier_mask_\n",
    "    return {\n",
    "        \"method\": \"ransac\",\n",
    "        \"n\": int(X.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": a,\n",
    "        \"b\": b,\n",
    "        \"c\": float(c),\n",
    "        \"inlier_frac\": float(np.mean(inlier_mask)),\n",
    "        \"residual_threshold\": residual_threshold,\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_loglog_binned_median(df, x_col, y_col, *, log_base=10, mask=None, bins=30, min_per_bin=20):\n",
    "    \"\"\"\n",
    "    Bin in log(x), compute median log(y) per bin, then OLS on bin summaries.\n",
    "    \"\"\"\n",
    "    from scipy import stats\n",
    "\n",
    "    _, _, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    # define bins in X\n",
    "    edges = np.linspace(X.min(), X.max(), bins + 1)\n",
    "    idx = np.digitize(X, edges) - 1\n",
    "    good = (idx >= 0) & (idx < bins)\n",
    "\n",
    "    Xb, Yb = [], []\n",
    "    for k in range(bins):\n",
    "        sel = good & (idx == k)\n",
    "        if np.sum(sel) >= min_per_bin:\n",
    "            Xb.append(np.median(X[sel]))\n",
    "            Yb.append(np.median(Y[sel]))\n",
    "\n",
    "    Xb = np.asarray(Xb)\n",
    "    Yb = np.asarray(Yb)\n",
    "    if Xb.size < 2:\n",
    "        raise ValueError(\"Not enough populated bins to fit binned median line.\")\n",
    "\n",
    "    res = stats.linregress(Xb, Yb)\n",
    "    a, b = res.intercept, res.slope\n",
    "    c = _line_params_to_powerlaw(a, b, log_base=log_base)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"binned_median\",\n",
    "        \"n\": int(X.size),\n",
    "        \"n_bins_used\": int(Xb.size),\n",
    "        \"mask\": m,\n",
    "        \"a\": float(a),\n",
    "        \"b\": float(b),\n",
    "        \"c\": float(c),\n",
    "        \"rvalue\": float(res.rvalue),\n",
    "    }\n",
    "\n",
    "\n",
    "def bootstrap_fit_ci(\n",
    "    fit_func, df, x_col, y_col, *, log_base=10, mask=None, n_boot=500, random_state=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic bootstrap CI for slope b and intercept a in log space.\n",
    "    fit_func should be one of the fit_* functions above (or compatible).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x_pos, y_pos, X, Y, m = _get_positive_xy(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "\n",
    "    n = X.size\n",
    "    a_s = np.empty(n_boot)\n",
    "    b_s = np.empty(n_boot)\n",
    "\n",
    "    # Work on arrays to avoid repeatedly touching the dataframe\n",
    "    # We'll create a lightweight dict-like view to reuse fit routines? simplest: resample indices and fit directly here.\n",
    "    # We'll just do OLS in bootstrap unless you want bootstrap for each robust method too.\n",
    "    # If you want method-specific bootstraps, it's doable but more compute.\n",
    "    for i in range(n_boot):\n",
    "        ii = rng.integers(0, n, size=n)\n",
    "        Xs = X[ii]\n",
    "        Ys = Y[ii]\n",
    "        # quick OLS in log space\n",
    "        b, a = np.polyfit(Xs, Ys, 1)\n",
    "        a_s[i] = a\n",
    "        b_s[i] = b\n",
    "\n",
    "    def ci(arr):\n",
    "        return (float(np.percentile(arr, 2.5)), float(np.percentile(arr, 97.5)))\n",
    "\n",
    "    return {\n",
    "        \"n\": int(n),\n",
    "        \"n_boot\": int(n_boot),\n",
    "        \"a_ci\": ci(a_s),\n",
    "        \"b_ci\": ci(b_s),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_logspace_edges(vmin: float, vmax: float, n_bins: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build integer-only edges approximating log spacing.\n",
    "\n",
    "    - Starts at max(1, floor(vmin)), ends at ceil(vmax)\n",
    "    - Each next edge follows a geometric ratio (vmax/vmin)^(1/n_bins)\n",
    "      but rounded to an integer, with at least +1 step.\n",
    "    - Guarantees strictly increasing integer edges and avoids skinny final bin.\n",
    "    \"\"\"\n",
    "    if vmin <= 0 or vmax <= 0:\n",
    "        raise ValueError(\"vmin and vmax must be > 0 for log spacing.\")\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax):\n",
    "        raise ValueError(\"vmin/vmax must be finite.\")\n",
    "    if n_bins < 1:\n",
    "        return np.array([np.floor(vmin), np.ceil(vmax)], dtype=float)\n",
    "\n",
    "    left = max(1.0, np.floor(vmin))\n",
    "    right = np.ceil(vmax)\n",
    "    r = (vmax / vmin) ** (1.0 / n_bins)\n",
    "\n",
    "    edges = [left]\n",
    "    i = 1\n",
    "    while edges[-1] < right and i <= 10_000:\n",
    "        target = vmin * (r**i)\n",
    "        next_edge = max(edges[-1] + 1.0, np.round(target))\n",
    "        if next_edge >= right:\n",
    "            edges.append(right)\n",
    "            break\n",
    "        edges.append(next_edge)\n",
    "        i += 1\n",
    "\n",
    "    if edges[-1] < right:\n",
    "        edges.append(right)\n",
    "    if len(edges) < 2:\n",
    "        edges = [left, right]\n",
    "\n",
    "    return np.array(edges, dtype=float)\n",
    "\n",
    "\n",
    "def compute_loglog_fit(df, x_col, y_col, *, method=\"huber\", log_base=10, mask=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Dispatch wrapper to compute a fit dict for log y = a + b log x.\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "    if method == \"ols\":\n",
    "        return fit_loglog_ols(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "    if method == \"tls\":\n",
    "        return fit_loglog_tls(df, x_col, y_col, log_base=log_base, mask=mask)\n",
    "    if method in (\"theil\", \"theilsen\", \"theil_sen\"):\n",
    "        return fit_loglog_theilsen(df, x_col, y_col, log_base=log_base, mask=mask, **kwargs)\n",
    "    if method == \"huber\":\n",
    "        return fit_loglog_huber(df, x_col, y_col, log_base=log_base, mask=mask, **kwargs)\n",
    "    if method == \"ransac\":\n",
    "        return fit_loglog_ransac(df, x_col, y_col, log_base=log_base, mask=mask, **kwargs)\n",
    "\n",
    "    raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "def overlay_loglog_fit(\n",
    "    ax,\n",
    "    fit,\n",
    "    *,\n",
    "    x_min=None,\n",
    "    x_max=None,\n",
    "    n=200,\n",
    "    color=\"#1a1a1a\",\n",
    "    lw=2.5,\n",
    "    ls=\"-\",\n",
    "    alpha=0.9,\n",
    "    label=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw y = c * x^b based on fit dict onto an existing log-log axis.\n",
    "    \"\"\"\n",
    "    b = fit[\"b\"]\n",
    "    c = fit[\"c\"]\n",
    "\n",
    "    if x_min is None or x_max is None:\n",
    "        lo, hi = ax.get_xlim()\n",
    "        x_min = lo if x_min is None else x_min\n",
    "        x_max = hi if x_max is None else x_max\n",
    "\n",
    "    xs = np.geomspace(x_min, x_max, n)\n",
    "    ys = c * (xs**b)\n",
    "\n",
    "    if label is None:\n",
    "        label = f\"{fit['method']}: y = {c:.3g}·x^{b:.3g}\"\n",
    "\n",
    "    ax.plot(xs, ys, color=color, lw=lw, ls=ls, alpha=alpha, label=label)\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "def two_d_histogram_int_bins(\n",
    "    df,\n",
    "    x_col=\"out_deg_true\",\n",
    "    y_col=\"priority\",\n",
    "    *,\n",
    "    gridsize=50,  # target number of approx log bins per axis\n",
    "    frac_guess=20,\n",
    "    title=\"Chat-by-chat: priority vs true out-degree, all languages\",\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Priority\",\n",
    "    figsize=(7, 6),\n",
    "    mincnt=1,\n",
    "    ylim=(1, None),\n",
    "    normalize_by_area=False,  # if True, divide by bin area (only when stat_col is None)\n",
    "    cscale=\"log\",  # \"log\" or \"linear\" color scale\n",
    "    stat_col=None,  # e.g. \"rank\"; if None, color by counts/density\n",
    "    stat_func=\"mean\",  # \"mean\" or \"median\" when stat_col is not None\n",
    "    fit_method=None,  # e.g. \"huber\", \"ols\", \"tls\", \"theil_sen\", \"ransac\", \"binned_median\"\n",
    "    fit_kwargs=None,  # dict of kwargs for the chosen fit\n",
    "    fit_color=\"#d62728\",  # overlay color (change if you want)\n",
    "    fit_label=None,\n",
    "    include_fit_box=False,  # optional textbox with slope/intercept\n",
    "    log_base=10,  # log base used for fitting (independent of axes)\n",
    "    ax=None,\n",
    "    labelsize=18,\n",
    "    legendsize=18,\n",
    "    include_stat_box=True,\n",
    "    cbar_labelsize=18,\n",
    "    legend_loc=\"upper right\",\n",
    "    show_minor_ticks=False,\n",
    "    reverse_colormap=False,\n",
    "    facecolor=\"white\",\n",
    "    include_diagonal=True,\n",
    "    include_legend=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Log-log density/count plot using integer-aligned, approx-log-spaced *rectangular* bins.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize_by_area : bool, default False\n",
    "        If True and stat_col is None, color shows counts divided by bin area (Δx·Δy).\n",
    "        If False, or if stat_col is not None, color does not divide by area.\n",
    "\n",
    "    cscale : {\"log\", \"linear\"}, default \"log\"\n",
    "        Color scale for the counts/densities/statistics.\n",
    "        - \"log\": logarithmic color scale via LogNorm; colorbar ticks at 10^x.\n",
    "        - \"linear\": linear color scale.\n",
    "\n",
    "    stat_col : str or None, default None\n",
    "        If None, color encodes bin counts (or area-normalized density).\n",
    "        If a column name, color encodes a statistic (mean/median) of this column\n",
    "        within each 2D bin.\n",
    "\n",
    "    stat_func : {\"mean\", \"median\"}, default \"mean\"\n",
    "        Statistic used on `stat_col` when stat_col is not None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax, frac_above, mask_pos\n",
    "    \"\"\"\n",
    "    # 1) Extract data\n",
    "    x = df[x_col].to_numpy(dtype=float)\n",
    "    y = df[y_col].to_numpy(dtype=float)\n",
    "\n",
    "    # 2) Keep only strictly positive values\n",
    "    mask_pos = (x > 0) & (y > 0)\n",
    "    x_pos, y_pos = x[mask_pos], y[mask_pos]\n",
    "\n",
    "    if x_pos.size == 0:\n",
    "        raise ValueError(\"No strictly positive points in both x and y.\")\n",
    "\n",
    "    # Fraction above y = x\n",
    "    frac_above = np.mean(y_pos > x_pos)\n",
    "    print(f\"Using {x_pos.size} points with x>0 and y>0\")\n",
    "    print(f\"Above the line y=x: {frac_above:.2%}\")\n",
    "\n",
    "    # If using a statistic, pull that column now (only for the positive-mask subset)\n",
    "    if stat_col is not None:\n",
    "        stat_vals = df.loc[mask_pos, stat_col].to_numpy(dtype=float)\n",
    "\n",
    "    # 3) Axes\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # 4) Integer-ish log edges\n",
    "    xedges = integer_logspace_edges(x_pos.min(), x_pos.max(), gridsize)\n",
    "    yedges = integer_logspace_edges(y_pos.min(), y_pos.max(), gridsize)\n",
    "\n",
    "    # 5) 2D histogram (raw counts)\n",
    "    H, xedges, yedges = np.histogram2d(x_pos, y_pos, bins=[xedges, yedges])\n",
    "\n",
    "    # 6) Build Z depending on whether we're using counts/density or a statistic\n",
    "    if stat_col is None:\n",
    "        # ---- Original behavior: counts or density ----\n",
    "        if normalize_by_area:\n",
    "            dx = np.diff(xedges)  # shape (Nx,)\n",
    "            dy = np.diff(yedges)  # shape (Ny,)\n",
    "            area = np.outer(dx, dy)  # shape (Nx, Ny), same as H\n",
    "\n",
    "            # avoid division by zero\n",
    "            area = np.where(area > 0, area, np.nan)\n",
    "\n",
    "            Z = H / area  # counts per unit x per unit y\n",
    "            # apply mincnt based on raw counts, like hexbin\n",
    "            Z[H < mincnt] = 0\n",
    "            base_label = \"density: count / (Δx·Δy)\"\n",
    "        else:\n",
    "            # keep raw counts\n",
    "            Z = H.copy()\n",
    "            Z[Z < mincnt] = 0\n",
    "            base_label = \"count per bin\"\n",
    "\n",
    "    else:\n",
    "        # ---- New behavior: statistic of another column per bin ----\n",
    "        if normalize_by_area:\n",
    "            print(\"Warning: normalize_by_area is ignored when stat_col is not None.\")\n",
    "\n",
    "        # Compute bin indices for each point\n",
    "        ix = np.digitize(x_pos, xedges) - 1  # 0..Nx-1, may be -1 or Nx\n",
    "        iy = np.digitize(y_pos, yedges) - 1  # 0..Ny-1, may be -1 or Ny\n",
    "\n",
    "        Nx = len(xedges) - 1\n",
    "        Ny = len(yedges) - 1\n",
    "\n",
    "        # Mask out-of-range indices (should be rare if edges span data)\n",
    "        valid = (ix >= 0) & (ix < Nx) & (iy >= 0) & (iy < Ny)\n",
    "        ix = ix[valid]\n",
    "        iy = iy[valid]\n",
    "        stat_vals_valid = stat_vals[valid]\n",
    "\n",
    "        # We'll accumulate values in each bin to compute mean/median\n",
    "        # Strategy: use a dictionary keyed by (ix, iy) to hold lists,\n",
    "        # then aggregate.\n",
    "        from collections import defaultdict\n",
    "\n",
    "        bin_values = defaultdict(list)\n",
    "        for bx, by, v in zip(ix, iy, stat_vals_valid):\n",
    "            bin_values[(bx, by)].append(v)\n",
    "\n",
    "        # Prepare Z as statistic per bin\n",
    "        Z = np.full((Nx, Ny), np.nan)\n",
    "\n",
    "        if stat_func not in {\"mean\", \"median\"}:\n",
    "            raise ValueError(\"stat_func must be 'mean' or 'median'\")\n",
    "\n",
    "        for (bx, by), vals in bin_values.items():\n",
    "            vals_arr = np.asarray(vals, dtype=float)\n",
    "            if stat_func == \"mean\":\n",
    "                Z[bx, by] = np.mean(vals_arr)\n",
    "            else:\n",
    "                Z[bx, by] = np.median(vals_arr)\n",
    "\n",
    "        # Apply mincnt threshold based on counts H\n",
    "        Z[H < mincnt] = np.nan\n",
    "\n",
    "        base_label = f\"{stat_func}({stat_col}) per bin\"\n",
    "\n",
    "    # Mask invalid / zero-or-less bins for plotting\n",
    "    if stat_col is None:\n",
    "        Z_plot = np.ma.masked_where(Z <= 0, Z)\n",
    "    else:\n",
    "        # For statistics, mask NaNs; if using log scale also mask <= 0\n",
    "        if cscale == \"log\":\n",
    "            Z_plot = np.ma.masked_where(~np.isfinite(Z) | (Z <= 0), Z)\n",
    "        else:\n",
    "            Z_plot = np.ma.masked_invalid(Z)\n",
    "    cmap = plt.get_cmap().reversed() if reverse_colormap else plt.get_cmap()\n",
    "    # 7) Plot with pcolormesh, choose color scale\n",
    "    if cscale == \"log\":\n",
    "        if Z_plot.size == 0 or np.all(Z_plot.mask):\n",
    "            raise ValueError(\"No positive values to plot on a log color scale.\")\n",
    "        vmin = Z_plot.min()\n",
    "        vmax = Z_plot.max()\n",
    "        mesh = ax.pcolormesh(\n",
    "            xedges,\n",
    "            yedges,\n",
    "            Z_plot.T,\n",
    "            norm=LogNorm(\n",
    "                vmin=vmin,\n",
    "                vmax=vmax,\n",
    "            ),\n",
    "            cmap=cmap,\n",
    "        )\n",
    "    elif cscale == \"linear\":\n",
    "        mesh = ax.pcolormesh(\n",
    "            xedges,\n",
    "            yedges,\n",
    "            Z_plot.T,\n",
    "            cmap=cmap,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"cscale must be 'log' or 'linear'\")\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    # Make sure limits are set before computing ticks\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    # ---- FORCE SAME MAJOR TICKS ON BOTH AXES ----\n",
    "    x_lo, x_hi = ax.get_xlim()\n",
    "    y_lo, y_hi = ax.get_ylim()\n",
    "\n",
    "    lo = min(x_lo, y_lo)\n",
    "    hi = max(x_hi, y_hi)\n",
    "\n",
    "    dec_min = int(np.floor(np.log10(lo)))\n",
    "    dec_max = int(np.ceil(np.log10(hi)))\n",
    "    decades = np.arange(dec_min, dec_max + 1)\n",
    "\n",
    "    # Major ticks: 10^dec\n",
    "    major_ticks = 10.0**decades\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_yticks(major_ticks)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", length=7)\n",
    "\n",
    "    # Analysis/fit\n",
    "    # 13) Optional fit overlay (in log-log space)\n",
    "    fit = None\n",
    "    if fit_method is not None:\n",
    "        if fit_kwargs is None:\n",
    "            fit_kwargs = {}\n",
    "\n",
    "        # use the same positive mask you already computed (mask_pos)\n",
    "        fit = compute_loglog_fit(\n",
    "            df,\n",
    "            x_col=x_col,\n",
    "            y_col=y_col,\n",
    "            method=fit_method,\n",
    "            log_base=log_base,\n",
    "            mask=mask_pos,\n",
    "            **fit_kwargs,\n",
    "        )\n",
    "\n",
    "        # Overlay on current axis range\n",
    "        overlay_loglog_fit(\n",
    "            ax,\n",
    "            fit,\n",
    "            color=fit_color,\n",
    "            label=fit_label,\n",
    "        )\n",
    "\n",
    "        if include_fit_box:\n",
    "            b = fit[\"b\"]\n",
    "            c = fit[\"c\"]\n",
    "            txt = f\"{fit['method']} fit\\nb = {b:.3g}\\nc = {c:.3g}\"\n",
    "            ax.text(\n",
    "                0.05,\n",
    "                1.02,\n",
    "                txt,\n",
    "                transform=ax.transAxes,\n",
    "                ha=\"left\",\n",
    "                va=\"bottom\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "                fontsize=legendsize,\n",
    "            )\n",
    "\n",
    "    # ---- OPTIONAL MINOR TICKS ----\n",
    "    if show_minor_ticks:\n",
    "        minor_ticks = []\n",
    "        for d in decades:\n",
    "            minor_ticks.extend((10.0**d) * np.arange(2, 10))\n",
    "        minor_ticks = np.array(minor_ticks)\n",
    "        minor_ticks = minor_ticks[(minor_ticks >= lo) & (minor_ticks <= hi)]\n",
    "\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        ax.set_yticks(minor_ticks, minor=True)\n",
    "\n",
    "        ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "        ax.yaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "        ax.tick_params(axis=\"both\", which=\"minor\", length=4)\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    ax.set_xlabel(x_label, fontsize=labelsize)\n",
    "    ax.set_ylabel(y_label, fontsize=labelsize)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # 8) 1:1 line\n",
    "    if include_diagonal:\n",
    "        lo_line = min(x_pos.min(), y_pos.min())\n",
    "        hi_line = max(x_pos.max(), y_pos.max())\n",
    "        ax.plot(\n",
    "            [lo_line, hi_line],\n",
    "            [lo_line, hi_line],\n",
    "            linewidth=2,\n",
    "            alpha=0.8,\n",
    "            label=\"y = x\",\n",
    "            color=\"#1a1a1a\",\n",
    "        )\n",
    "\n",
    "    # 9) Reference slope(s)\n",
    "    frac_between = None\n",
    "\n",
    "    if frac_guess is not None:\n",
    "        xgrid = np.array([x_pos.min(), x_pos.max()])\n",
    "\n",
    "        # Case 1: single scalar (original behavior)\n",
    "        if np.isscalar(frac_guess):\n",
    "            ax.plot(\n",
    "                xgrid,\n",
    "                xgrid / frac_guess,\n",
    "                label=f\"y = x/{frac_guess}\",\n",
    "                linestyle=\"dashdot\",\n",
    "                linewidth=2,\n",
    "                color=\"#1a1a1a\",\n",
    "            )\n",
    "\n",
    "        # Case 2: two values → band between two lines\n",
    "        else:\n",
    "            try:\n",
    "                f1, f2 = sorted(frac_guess)\n",
    "            except Exception:\n",
    "                raise ValueError(\"frac_guess must be a scalar or an iterable of two numbers\")\n",
    "\n",
    "            if f1 <= 0 or f2 <= 0:\n",
    "                raise ValueError(\"frac_guess values must be positive\")\n",
    "\n",
    "            # Draw both lines\n",
    "            ax.plot(\n",
    "                xgrid,\n",
    "                xgrid / f1,\n",
    "                linestyle=\"dashdot\",\n",
    "                linewidth=2,\n",
    "                label=f\"y = x/{f1}\",\n",
    "                color=\"#1a1a1a\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                xgrid,\n",
    "                xgrid / f2,\n",
    "                linestyle=\"dotted\",\n",
    "                linewidth=2,\n",
    "                label=f\"y = x/{f2}\",\n",
    "                color=\"#1a1a1a\",\n",
    "            )\n",
    "\n",
    "            # Compute fraction of points between the two lines\n",
    "            lower = x_pos / f2\n",
    "            upper = x_pos / f1\n",
    "            frac_between = np.mean((y_pos >= lower) & (y_pos <= upper))\n",
    "\n",
    "    # 10) Colorbar\n",
    "    cb = fig.colorbar(mesh, ax=ax)\n",
    "\n",
    "    if cscale == \"log\":\n",
    "        cb.locator = LogLocator(base=10)\n",
    "        cb.formatter = LogFormatterMathtext(base=10)  # shows 10^x\n",
    "        cb.update_ticks()\n",
    "        cb.set_label(base_label, fontsize=cbar_labelsize, rotation=270, labelpad=20)\n",
    "    else:\n",
    "        cb.set_label(base_label, fontsize=cbar_labelsize, rotation=270, labelpad=20)\n",
    "\n",
    "    # 11) Annotate fractions\n",
    "    annotation_lines = [f\"y > x: {frac_above:.1%}\"]\n",
    "\n",
    "    if frac_between is not None:\n",
    "        annotation_lines.append(f\"x/{f2} ≤ y ≤ x/{f1}: {frac_between:.1%}\")\n",
    "    print(f\"x/{f2} ≤ y ≤ x/{f1}: {frac_between:.1%}\")\n",
    "    if include_stat_box:\n",
    "        ax.text(\n",
    "            0.05,\n",
    "            1.15,\n",
    "            \"\\n\".join(annotation_lines),\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"left\",\n",
    "            va=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "            fontsize=legendsize,\n",
    "        )\n",
    "\n",
    "    # 12) Cosmetics\n",
    "    if include_legend:  # Don't show the legend box, if not content\n",
    "        ax.legend(fontsize=legendsize, loc=legend_loc)\n",
    "    ax.grid(True, which=\"major\", ls=\"--\", alpha=0.4, color=\"k\")\n",
    "    ax.set_facecolor(facecolor)\n",
    "    if show_minor_ticks:\n",
    "        ax.grid(True, which=\"minor\", ls=\"--\", alpha=0.25)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax, frac_above, mask_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf056f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database setup\n",
    "db_user = os.environ.get(\"DB_USER\")\n",
    "db_pass = os.environ.get(\"DB_PASSWORD\")\n",
    "db_host = os.environ.get(\"DB_HOST\")\n",
    "db_port = os.environ.get(\"DB_PORT\")\n",
    "db_name = os.environ.get(\"DB_NAME\")\n",
    "\n",
    "db_url = f'postgresql+psycopg2://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}'\n",
    "\n",
    "# Dask can't work with ORM models\n",
    "message_table = Message.__table__\n",
    "chat_table = Chat.__table__\n",
    "queue_table = Queue.__table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    db_url,\n",
    "    pool_pre_ping=True,  # good for long streaming jobs\n",
    "    future=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ff617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang = pd.read_parquet(\"../../data/chat_languages.parquet\")\n",
    "if df_lang.index.name == \"chat_id\" and \"chat_id\" not in df_lang.columns:\n",
    "    df_lang = df_lang.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca020ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = \"1 hour\"\n",
    "\n",
    "if time_window == \"1 hour\":\n",
    "    delta_seconds = 60 * 60\n",
    "elif time_window == \"1 day\":\n",
    "    delta_seconds = 60 * 60 * 24\n",
    "elif time_window == \"1 week\":\n",
    "    delta_seconds = 60 * 60 * 24 * 7\n",
    "elif time_window == \"0\":\n",
    "    delta_seconds = 0\n",
    "elif time_window == \"inf\":\n",
    "    delta_seconds = 1e9\n",
    "else:\n",
    "    raise ValueError(\"Unknown time window\")\n",
    "\n",
    "# df = con.execute(f\"\"\"\n",
    "# WITH base AS (\n",
    "#   SELECT src, sender, ts\n",
    "#   FROM read_parquet('../../data/edges_sorted.parquet')\n",
    "#   WHERE ts IS NOT NULL\n",
    "# ),\n",
    "# with_prev AS (\n",
    "#   SELECT\n",
    "#     src,\n",
    "#     sender,\n",
    "#     ts,\n",
    "#     lag(ts) OVER (PARTITION BY src, sender ORDER BY ts) AS prev_ts\n",
    "#   FROM base\n",
    "# ),\n",
    "# outdeg AS (\n",
    "#   SELECT\n",
    "#     src,\n",
    "#     CAST(SUM(\n",
    "#       CASE\n",
    "#         WHEN prev_ts IS NULL THEN 1\n",
    "#         WHEN ts - prev_ts > INTERVAL '{delta_seconds} seconds' THEN 1\n",
    "#         ELSE 0\n",
    "#       END\n",
    "#     ) AS BIGINT) AS out_degree\n",
    "#   FROM with_prev\n",
    "#   GROUP BY src\n",
    "# )\n",
    "# SELECT\n",
    "#   o.src,\n",
    "#   o.out_degree,\n",
    "#   c.true_out_deg,\n",
    "#   c.rank\n",
    "# FROM outdeg o\n",
    "# LEFT JOIN read_parquet('../../data/rank_degree.parquet') c\n",
    "#   ON o.src = c.chat_id\n",
    "# ORDER BY o.out_degree DESC\n",
    "# \"\"\").df()\n",
    "\n",
    "df = con.execute(\n",
    "    f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT src, sender, ts\n",
    "  FROM read_parquet('../../data/edges_sorted.parquet')\n",
    "  WHERE ts IS NOT NULL\n",
    "    AND src_is_chat = 1\n",
    "),\n",
    "with_prev AS (\n",
    "  SELECT\n",
    "    src,\n",
    "    sender,\n",
    "    ts,\n",
    "    lag(ts) OVER (PARTITION BY src, sender ORDER BY ts) AS prev_ts\n",
    "  FROM base\n",
    "),\n",
    "outdeg AS (\n",
    "  SELECT\n",
    "    src,\n",
    "    CAST(SUM(\n",
    "      CASE\n",
    "        WHEN prev_ts IS NULL THEN 1\n",
    "        WHEN ts - prev_ts > INTERVAL '{delta_seconds} seconds' THEN 1\n",
    "        ELSE 0\n",
    "      END\n",
    "    ) AS BIGINT) AS out_degree\n",
    "  FROM with_prev\n",
    "  GROUP BY src\n",
    ")\n",
    "SELECT\n",
    "  o.src,\n",
    "  o.out_degree,\n",
    "  c.true_out_deg,\n",
    "  c.rank\n",
    "FROM outdeg o\n",
    "LEFT JOIN read_parquet('../../data/rank_degree.parquet') c\n",
    "  ON o.src = c.chat_id\n",
    "ORDER BY o.out_degree DESC\n",
    "\"\"\"\n",
    ").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec38e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_chats = False\n",
    "if only_chats:\n",
    "    df = df[df[\"src_is_chat\"] == 1].copy()\n",
    "\n",
    "gray_name = \"#333533\"\n",
    "fig, ax, frac_above, mask_pos = two_d_histogram_int_bins(\n",
    "    df,\n",
    "    x_col=\"true_out_deg\",\n",
    "    y_col=\"out_degree\",\n",
    "    gridsize=40,\n",
    "    title=None,\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Recorded out-degree\",\n",
    "    cscale=\"linear\",\n",
    "    frac_guess=[5, 200],\n",
    "    legendsize=15,\n",
    "    legend_loc=\"upper left\",\n",
    "    cbar_labelsize=15,\n",
    "    reverse_colormap=True,\n",
    "    include_stat_box=False,\n",
    "    stat_col=\"rank\",\n",
    "    include_legend=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61607551",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.get_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d24097",
   "metadata": {},
   "source": [
    "# Correlation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, frac_above, mask_pos = two_d_histogram_int_bins(\n",
    "    df,\n",
    "    x_col=\"true_out_deg\",\n",
    "    y_col=\"out_degree\",\n",
    "    gridsize=40,\n",
    "    title=None,\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Recorded out-degree\",\n",
    "    cscale=\"log\",\n",
    "    frac_guess=[5, 200],\n",
    "    legendsize=15,\n",
    "    legend_loc=\"upper left\",\n",
    "    cbar_labelsize=15,\n",
    "    reverse_colormap=True,\n",
    "    include_stat_box=False,\n",
    "    # stat_col=\"rank\",\n",
    "    include_legend=False,\n",
    "    # NEW:\n",
    "    fit_method=\"ransac\",\n",
    "    fit_kwargs={\"min_samples\": 0.5, \"residual_threshold\": 0.3},\n",
    "    fit_color=\"#e41a1c\",\n",
    "    include_fit_box=True,\n",
    "    log_base=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_median_loglog_plot(\n",
    "    df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    *,\n",
    "    bins=40,  # number of log-x bins\n",
    "    x_edges=None,  # optional explicit bin edges (overrides bins)\n",
    "    min_per_bin=50,  # drop bins with fewer points\n",
    "    quantiles=(0.25, 0.75),  # band around median; set None for no band\n",
    "    log_base=10,  # for binning in log space (axes are still log)\n",
    "    figsize=(7, 6),\n",
    "    title=None,\n",
    "    x_label=None,\n",
    "    y_label=None,\n",
    "    ax=None,\n",
    "    show_points=True,\n",
    "    connect=True,  # connect medians with a line\n",
    "    show_band=True,\n",
    "    band_alpha=0.2,\n",
    "    # Optional overlay of a fit in log-log space to the BIN MEDIANS\n",
    "    fit_method=None,  # \"ols\" or \"tls\" are easy here; see below\n",
    "    fit_to=\"binned\",  # \"binned\" (default) or \"raw\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot median y in log-spaced bins of x (log-log axes).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax, summary\n",
    "      summary is a dict with arrays for bin centers/medians/etc.\n",
    "    \"\"\"\n",
    "    x = df[x_col].to_numpy(dtype=float)\n",
    "    y = df[y_col].to_numpy(dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "    if x.size == 0:\n",
    "        raise ValueError(\"No strictly positive finite points in both x and y.\")\n",
    "\n",
    "    # Choose log function for binning\n",
    "    if log_base == 10:\n",
    "        lx = np.log10(x)\n",
    "    elif log_base in (np.e, None):\n",
    "        lx = np.log(x)\n",
    "    else:\n",
    "        lx = np.log(x) / np.log(log_base)\n",
    "\n",
    "    # Build bin edges in log-x\n",
    "    if x_edges is None:\n",
    "        edges_lx = np.linspace(lx.min(), lx.max(), bins + 1)\n",
    "    else:\n",
    "        # interpret x_edges as ORIGINAL-scale edges, convert to log\n",
    "        x_edges = np.asarray(x_edges, dtype=float)\n",
    "        if np.any(x_edges <= 0):\n",
    "            raise ValueError(\"All x_edges must be > 0 for log binning.\")\n",
    "        if log_base == 10:\n",
    "            edges_lx = np.log10(x_edges)\n",
    "        elif log_base in (np.e, None):\n",
    "            edges_lx = np.log(x_edges)\n",
    "        else:\n",
    "            edges_lx = np.log(x_edges) / np.log(log_base)\n",
    "\n",
    "    # Assign points to bins\n",
    "    idx = np.digitize(lx, edges_lx) - 1\n",
    "    nb = len(edges_lx) - 1\n",
    "    good = (idx >= 0) & (idx < nb)\n",
    "\n",
    "    # Summarize each bin\n",
    "    x_med, y_med, counts = [], [], []\n",
    "    y_lo, y_hi = [], []\n",
    "\n",
    "    for k in range(nb):\n",
    "        sel = good & (idx == k)\n",
    "        n = int(np.sum(sel))\n",
    "        if n < min_per_bin:\n",
    "            continue\n",
    "\n",
    "        xs = x[sel]\n",
    "        ys = y[sel]\n",
    "\n",
    "        x_med.append(np.median(xs))\n",
    "        y_med.append(np.median(ys))\n",
    "        counts.append(n)\n",
    "\n",
    "        if quantiles is not None:\n",
    "            qlo, qhi = quantiles\n",
    "            y_lo.append(np.quantile(ys, qlo))\n",
    "            y_hi.append(np.quantile(ys, qhi))\n",
    "\n",
    "    x_med = np.asarray(x_med)\n",
    "    y_med = np.asarray(y_med)\n",
    "    counts = np.asarray(counts)\n",
    "\n",
    "    if x_med.size < 2:\n",
    "        raise ValueError(\"Not enough populated bins to plot (try fewer bins or lower min_per_bin).\")\n",
    "\n",
    "    if quantiles is not None:\n",
    "        y_lo = np.asarray(y_lo)\n",
    "        y_hi = np.asarray(y_hi)\n",
    "\n",
    "    # Make axes\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # Plot band first\n",
    "    if show_band and quantiles is not None:\n",
    "        ax.fill_between(x_med, y_lo, y_hi, alpha=band_alpha)\n",
    "\n",
    "    # Plot median points (optionally connected)\n",
    "    if connect:\n",
    "        ax.plot(x_med, y_med, marker=\"o\" if show_points else None)\n",
    "    elif show_points:\n",
    "        ax.scatter(x_med, y_med)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlabel(x_label if x_label is not None else x_col)\n",
    "    ax.set_ylabel(y_label if y_label is not None else y_col)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    # Optional fit overlay\n",
    "    fit = None\n",
    "    if fit_method is not None:\n",
    "        fit_method = fit_method.lower()\n",
    "\n",
    "        # Decide what to fit to: binned medians or raw points\n",
    "        if fit_to == \"binned\":\n",
    "            Xfit = (\n",
    "                np.log10(x_med)\n",
    "                if log_base == 10\n",
    "                else (\n",
    "                    np.log(x_med) if log_base in (np.e, None) else np.log(x_med) / np.log(log_base)\n",
    "                )\n",
    "            )\n",
    "            Yfit = (\n",
    "                np.log10(y_med)\n",
    "                if log_base == 10\n",
    "                else (\n",
    "                    np.log(y_med) if log_base in (np.e, None) else np.log(y_med) / np.log(log_base)\n",
    "                )\n",
    "            )\n",
    "        elif fit_to == \"raw\":\n",
    "            Xfit = lx\n",
    "            # log of y in same base\n",
    "            if log_base == 10:\n",
    "                Yfit = np.log10(y)\n",
    "            elif log_base in (np.e, None):\n",
    "                Yfit = np.log(y)\n",
    "            else:\n",
    "                Yfit = np.log(y) / np.log(log_base)\n",
    "        else:\n",
    "            raise ValueError(\"fit_to must be 'binned' or 'raw'\")\n",
    "\n",
    "        if fit_method == \"ols\":\n",
    "            b, a = np.polyfit(Xfit, Yfit, 1)  # slope, intercept\n",
    "        elif fit_method == \"tls\":\n",
    "            Xc = Xfit - Xfit.mean()\n",
    "            Yc = Yfit - Yfit.mean()\n",
    "            A = np.vstack([Xc, Yc]).T\n",
    "            _, _, Vt = np.linalg.svd(A, full_matrices=False)\n",
    "            vx, vy = Vt[0, 0], Vt[0, 1]\n",
    "            if np.isclose(vx, 0):\n",
    "                raise ValueError(\"TLS failed: near-vertical line in log space.\")\n",
    "            b = vy / vx\n",
    "            a = Yfit.mean() - b * Xfit.mean()\n",
    "        else:\n",
    "            raise ValueError(\"fit_method must be 'ols' or 'tls' in this standalone plot.\")\n",
    "\n",
    "        # Convert to y = c * x^b\n",
    "        if log_base == 10:\n",
    "            c = 10**a\n",
    "        elif log_base in (np.e, None):\n",
    "            c = np.exp(a)\n",
    "        else:\n",
    "            c = log_base**a\n",
    "\n",
    "        # draw fit over current x-range\n",
    "        xmin, xmax = ax.get_xlim()\n",
    "        xs = np.geomspace(xmin, xmax, 200)\n",
    "        ys = c * (xs**b)\n",
    "        ax.plot(xs, ys, linestyle=\"--\", linewidth=2, label=f\"{fit_method}: y={c:.3g}·x^{b:.3g}\")\n",
    "        ax.legend()\n",
    "\n",
    "        fit = {\"method\": fit_method, \"a\": float(a), \"b\": float(b), \"c\": float(c), \"fit_to\": fit_to}\n",
    "\n",
    "    ax.grid(True, which=\"major\", ls=\"--\", alpha=0.4)\n",
    "\n",
    "    summary = {\n",
    "        \"x_median\": x_med,\n",
    "        \"y_median\": y_med,\n",
    "        \"count\": counts,\n",
    "        \"quantiles\": quantiles,\n",
    "    }\n",
    "    if quantiles is not None:\n",
    "        summary[\"y_qlo\"] = y_lo\n",
    "        summary[\"y_qhi\"] = y_hi\n",
    "    if fit is not None:\n",
    "        summary[\"fit\"] = fit\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, summary = binned_median_loglog_plot(\n",
    "    df,\n",
    "    x_col=\"true_out_deg\",\n",
    "    y_col=\"out_degree\",\n",
    "    bins=40,\n",
    "    min_per_bin=200,\n",
    "    quantiles=(0.25, 0.75),  # IQR band\n",
    "    title=\"Binned-median trend: Recorded vs True out-degree\",\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Recorded out-degree\",\n",
    "    fit_method=\"tls\",  # try \"ols\" or \"tls\"\n",
    "    fit_to=\"binned\",  # fit line to binned medians\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def binned_mean_std_loglog_plot(\n",
    "    df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    *,\n",
    "    bins=40,\n",
    "    x_edges=None,  # optional explicit ORIGINAL-scale edges; overrides bins\n",
    "    min_per_bin=50,\n",
    "    log_base=10,\n",
    "    band=\"std\",  # \"std\" or \"sem\" or None\n",
    "    figsize=(7, 6),\n",
    "    title=None,\n",
    "    x_label=None,\n",
    "    y_label=None,\n",
    "    ax=None,\n",
    "    connect=True,\n",
    "    show_points=True,\n",
    "    band_alpha=0.2,\n",
    "    clip_lower_at=0.0,  # for log y, negative/zero bands are invalid; we'll clip to this\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot binned mean(y) in log-spaced bins of x, with band = ±std or ±sem.\n",
    "\n",
    "    Returns fig, ax, summary dict with per-bin stats.\n",
    "    \"\"\"\n",
    "    x = df[x_col].to_numpy(dtype=float)\n",
    "    y = df[y_col].to_numpy(dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "    if x.size == 0:\n",
    "        raise ValueError(\"No strictly positive finite points in both x and y.\")\n",
    "\n",
    "    # log-x for binning\n",
    "    if log_base == 10:\n",
    "        lx = np.log10(x)\n",
    "    elif log_base in (np.e, None):\n",
    "        lx = np.log(x)\n",
    "    else:\n",
    "        lx = np.log(x) / np.log(log_base)\n",
    "\n",
    "    # bin edges in log-x\n",
    "    if x_edges is None:\n",
    "        edges_lx = np.linspace(lx.min(), lx.max(), bins + 1)\n",
    "    else:\n",
    "        x_edges = np.asarray(x_edges, dtype=float)\n",
    "        if np.any(x_edges <= 0):\n",
    "            raise ValueError(\"All x_edges must be > 0.\")\n",
    "        if log_base == 10:\n",
    "            edges_lx = np.log10(x_edges)\n",
    "        elif log_base in (np.e, None):\n",
    "            edges_lx = np.log(x_edges)\n",
    "        else:\n",
    "            edges_lx = np.log(x_edges) / np.log(log_base)\n",
    "\n",
    "    idx = np.digitize(lx, edges_lx) - 1\n",
    "    nb = len(edges_lx) - 1\n",
    "    good = (idx >= 0) & (idx < nb)\n",
    "\n",
    "    x_center, y_mean, y_std, y_lo, y_hi, counts = [], [], [], [], [], []\n",
    "\n",
    "    for k in range(nb):\n",
    "        sel = good & (idx == k)\n",
    "        n = int(np.sum(sel))\n",
    "        if n < min_per_bin:\n",
    "            continue\n",
    "\n",
    "        xs = x[sel]\n",
    "        ys = y[sel]\n",
    "\n",
    "        xm = np.mean(xs)  # could also use geometric mean: np.exp(np.mean(np.log(xs)))\n",
    "        mu = np.mean(ys)\n",
    "\n",
    "        # sample std (ddof=1) if n>1 else 0\n",
    "        sd = np.std(ys, ddof=1) if n > 1 else 0.0\n",
    "\n",
    "        x_center.append(xm)\n",
    "        y_mean.append(mu)\n",
    "        y_std.append(sd)\n",
    "        counts.append(n)\n",
    "\n",
    "        if band is not None:\n",
    "            if band == \"std\":\n",
    "                err = sd\n",
    "            elif band == \"sem\":\n",
    "                err = sd / np.sqrt(n)\n",
    "            else:\n",
    "                raise ValueError(\"band must be 'std', 'sem', or None\")\n",
    "\n",
    "            lo = mu - err\n",
    "            hi = mu + err\n",
    "\n",
    "            # On log y-axis, values must be > 0\n",
    "            lo = max(lo, clip_lower_at)\n",
    "            y_lo.append(lo)\n",
    "            y_hi.append(hi)\n",
    "\n",
    "    x_center = np.asarray(x_center)\n",
    "    y_mean = np.asarray(y_mean)\n",
    "    y_std = np.asarray(y_std)\n",
    "    counts = np.asarray(counts)\n",
    "\n",
    "    if x_center.size < 2:\n",
    "        raise ValueError(\"Not enough populated bins to plot (try fewer bins or lower min_per_bin).\")\n",
    "\n",
    "    if band is not None:\n",
    "        y_lo = np.asarray(y_lo)\n",
    "        y_hi = np.asarray(y_hi)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # band first\n",
    "    if band is not None:\n",
    "        # If clip_lower_at==0, some lo might be 0 -> invalid on log axis.\n",
    "        # Replace nonpositive lo with nan so fill_between doesn't blow up.\n",
    "        lo_plot = y_lo.copy()\n",
    "        lo_plot[lo_plot <= 0] = np.nan\n",
    "        ax.fill_between(x_center, lo_plot, y_hi, alpha=band_alpha, label=f\"±{band}\")\n",
    "\n",
    "    # mean curve / points\n",
    "    if connect:\n",
    "        ax.plot(x_center, y_mean, marker=\"o\" if show_points else None, label=\"binned mean\")\n",
    "    elif show_points:\n",
    "        ax.scatter(x_center, y_mean, label=\"binned mean\")\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlabel(x_label if x_label is not None else x_col)\n",
    "    ax.set_ylabel(y_label if y_label is not None else y_col)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.grid(True, which=\"major\", ls=\"--\", alpha=0.4)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    summary = {\n",
    "        \"x_center\": x_center,\n",
    "        \"y_mean\": y_mean,\n",
    "        \"y_std\": y_std,\n",
    "        \"count\": counts,\n",
    "        \"band\": band,\n",
    "    }\n",
    "    if band is not None:\n",
    "        summary[\"y_lo\"] = y_lo\n",
    "        summary[\"y_hi\"] = y_hi\n",
    "\n",
    "    return fig, ax, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, summary = binned_mean_std_loglog_plot(\n",
    "    df,\n",
    "    x_col=\"true_out_deg\",\n",
    "    y_col=\"out_degree\",\n",
    "    bins=40,\n",
    "    min_per_bin=200,\n",
    "    band=\"std\",  # or \"sem\" or None\n",
    "    title=\"Binned mean ± std (log–log)\",\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Recorded out-degree\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d16dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _log_edges(vmin, vmax, bins, base=10):\n",
    "    if vmin <= 0 or vmax <= 0:\n",
    "        raise ValueError(\"log bins require vmin>0 and vmax>0\")\n",
    "    if base == 10:\n",
    "        return np.logspace(np.log10(vmin), np.log10(vmax), bins + 1)\n",
    "    elif base in (np.e, None):\n",
    "        return np.exp(np.linspace(np.log(vmin), np.log(vmax), bins + 1))\n",
    "    else:\n",
    "        ln = np.log\n",
    "        return np.exp(\n",
    "            np.linspace(ln(vmin), ln(vmax), bins + 1)\n",
    "        )  # edges are in natural units; base doesn’t matter for spacing\n",
    "\n",
    "\n",
    "def ridge_max_ybin_per_xbin(\n",
    "    df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    *,\n",
    "    x_bins=40,\n",
    "    y_bins=40,\n",
    "    x_edges=None,  # optional explicit edges (original scale)\n",
    "    y_edges=None,\n",
    "    log_base=10,\n",
    "    mincnt_x=1,  # require at least this many points in an x-bin to report a ridge point\n",
    "    tie_break=\"lower\",  # \"lower\", \"upper\", or \"center\" if multiple y-bins share the max\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute ridge points from a 2D histogram: for each x-bin choose y-bin with max count.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ridge : dict with keys\n",
    "      x_centers, y_centers, peak_counts, xbin_counts, H, x_edges, y_edges, mask_pos\n",
    "    \"\"\"\n",
    "    x = df[x_col].to_numpy(dtype=float)\n",
    "    y = df[y_col].to_numpy(dtype=float)\n",
    "    mask_pos = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)\n",
    "    x = x[mask_pos]\n",
    "    y = y[mask_pos]\n",
    "    if x.size == 0:\n",
    "        raise ValueError(\"No strictly positive finite points in both x and y.\")\n",
    "\n",
    "    if x_edges is None:\n",
    "        x_edges = _log_edges(x.min(), x.max(), x_bins, base=log_base)\n",
    "    else:\n",
    "        x_edges = np.asarray(x_edges, dtype=float)\n",
    "\n",
    "    if y_edges is None:\n",
    "        y_edges = _log_edges(y.min(), y.max(), y_bins, base=log_base)\n",
    "    else:\n",
    "        y_edges = np.asarray(y_edges, dtype=float)\n",
    "\n",
    "    H, x_edges, y_edges = np.histogram2d(x, y, bins=[x_edges, y_edges])  # H shape (Nx, Ny)\n",
    "    H = H.astype(int)\n",
    "\n",
    "    # bin centers (geometric mean is natural for log bins)\n",
    "    x_centers = np.sqrt(x_edges[:-1] * x_edges[1:])\n",
    "    y_centers = np.sqrt(y_edges[:-1] * y_edges[1:])\n",
    "\n",
    "    Nx, Ny = H.shape\n",
    "    peak_y_idx = np.full(Nx, -1, dtype=int)\n",
    "    peak_counts = np.zeros(Nx, dtype=int)\n",
    "    xbin_counts = H.sum(axis=1)\n",
    "\n",
    "    for i in range(Nx):\n",
    "        if xbin_counts[i] < mincnt_x:\n",
    "            continue\n",
    "\n",
    "        col = H[i, :]\n",
    "        maxv = col.max()\n",
    "        if maxv <= 0:\n",
    "            continue\n",
    "\n",
    "        js = np.flatnonzero(col == maxv)\n",
    "        if js.size == 1:\n",
    "            j = int(js[0])\n",
    "        else:\n",
    "            if tie_break == \"lower\":\n",
    "                j = int(js.min())\n",
    "            elif tie_break == \"upper\":\n",
    "                j = int(js.max())\n",
    "            elif tie_break == \"center\":\n",
    "                j = int(js[js.size // 2])\n",
    "            else:\n",
    "                raise ValueError(\"tie_break must be 'lower', 'upper', or 'center'\")\n",
    "\n",
    "        peak_y_idx[i] = j\n",
    "        peak_counts[i] = maxv\n",
    "\n",
    "    keep = peak_y_idx >= 0\n",
    "    return {\n",
    "        \"x_ridge\": x_centers[keep],\n",
    "        \"y_ridge\": y_centers[peak_y_idx[keep]],\n",
    "        \"peak_counts\": peak_counts[keep],\n",
    "        \"xbin_counts\": xbin_counts[keep],\n",
    "        \"H\": H,\n",
    "        \"x_edges\": x_edges,\n",
    "        \"y_edges\": y_edges,\n",
    "        \"mask_pos\": mask_pos,\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_ridge(\n",
    "    ridge,\n",
    "    *,\n",
    "    ax=None,\n",
    "    figsize=(7, 6),\n",
    "    title=None,\n",
    "    x_label=\"x\",\n",
    "    y_label=\"y\",\n",
    "    show_sizes=True,  # point size proportional to peak count\n",
    "    show_color=False,  # point color proportional to peak count\n",
    "    connect=True,\n",
    "):\n",
    "    x_r = ridge[\"x_ridge\"]\n",
    "    y_r = ridge[\"y_ridge\"]\n",
    "    pc = ridge[\"peak_counts\"]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    if show_sizes:\n",
    "        # scale marker sizes gently\n",
    "        s = 20 + 80 * (pc / pc.max() if pc.max() > 0 else 1.0)\n",
    "    else:\n",
    "        s = 30\n",
    "\n",
    "    if show_color:\n",
    "        sc = ax.scatter(x_r, y_r, s=s, c=pc)\n",
    "        fig.colorbar(sc, ax=ax, label=\"peak bin count\")\n",
    "        if connect:\n",
    "            ax.plot(x_r, y_r, alpha=0.5)\n",
    "    else:\n",
    "        if connect:\n",
    "            ax.plot(x_r, y_r, marker=\"o\", markersize=4)\n",
    "        else:\n",
    "            ax.scatter(x_r, y_r, s=s)\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.grid(True, which=\"major\", ls=\"--\", alpha=0.4)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = ridge_max_ybin_per_xbin(\n",
    "    df,\n",
    "    x_col=\"true_out_deg\",\n",
    "    y_col=\"out_degree\",\n",
    "    x_bins=30,\n",
    "    y_bins=30,\n",
    "    mincnt_x=50,  # ignore x-bins with <50 points total\n",
    "    tie_break=\"lower\",\n",
    ")\n",
    "\n",
    "fig, ax = plot_ridge(\n",
    "    ridge,\n",
    "    title=\"Ridge: y-bin with max count per x-bin\",\n",
    "    x_label=\"True out-degree\",\n",
    "    y_label=\"Recorded out-degree\",\n",
    "    show_sizes=True,\n",
    "    show_color=False,\n",
    "    connect=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a3e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram-quality-control-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
